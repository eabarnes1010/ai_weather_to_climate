{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3f1356-f153-4c24-b3a9-a0e80d461844",
   "metadata": {},
   "source": [
    "# Example illustrating different forecast evaluation statistics for precipitation\n",
    "\n",
    "## This is part 2; expects that data have already been preprocessed using part 1, with a netcdf file written out\n",
    "\n",
    "## We'll use the heavy rainfall in eastern Colorado from 21-22 June 2023 for the example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57acc0dc-39a0-4421-aa46-c0604aa912f2",
   "metadata": {},
   "source": [
    "[![Latest release](https://badgen.net/github/release/Naereen/Strapdown.js)](https://github.com/eabarnes1010/ai_weather_to_climate_ats780A8/tree/main/lecture_code)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eabarnes1010/ai_weather_to_climate_ats780A8/blob/main/lecture_code/precip_verif_example.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6033b-6861-43db-b9bf-879489de54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cartopy metpy plotly netcdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f619b6-9a02-4b76-a3fb-85522d452c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fsspec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import (LongitudeFormatter, LatitudeFormatter,\n",
    "                                LatitudeLocator)\n",
    "\n",
    "import metpy.calc as mpcalc\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97346b9-8352-47ca-bf1e-9f24492c1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtime = pd.Timestamp(2023,6,22,12) ### valid time\n",
    "\n",
    "fxx = 24 ### what lead time do we want to evaluate? (in hours)\n",
    "\n",
    "init = vtime - pd.Timedelta(hours=fxx)   ### this will give us the forecasts from 12 UTC 21 June (a 24-h forecast)\n",
    "init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15095e3c-9439-4aea-aeca-271b18bad3f7",
   "metadata": {},
   "source": [
    "## Read in the netcdf we wrote in the other part. Need to use fsspec because xarray doesn't support this directly (see https://github.com/pydata/xarray/issues/3653) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b0e3d-1105-4219-85e4-b0e18a07e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/eabarnes1010/ai_weather_to_climate_ats780A8/raw/main/lecture_code/precip_data_preproc_2023062212.nc#mode=bytes\"\n",
    "\n",
    "with fsspec.open(url) as fobj:\n",
    "    data_all = xr.open_dataset(fobj)\n",
    "\n",
    "data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b93d5f-48f4-49a9-aa25-363b5704e122",
   "metadata": {},
   "source": [
    "### subset data spatially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b3a61-c0ec-40ef-9a5a-0068ca4d8512",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up some borders to subset the data\n",
    "minlon = -108.\n",
    "maxlon = -101.\n",
    "minlat = 36.\n",
    "maxlat = 42.\n",
    "\n",
    "data_sub = data_all.sel(lon=slice(minlon-2,maxlon+2), lat=slice(minlat-2,maxlat+2))\n",
    "data_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8190fc-dc29-4ed8-ad5e-c18fe0593c30",
   "metadata": {},
   "source": [
    "### set up the color table and map background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10164e2-cb1a-4b36-a3bf-f8ff1a0f4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up NWS color table\n",
    "cmap_data = [(1.000000, 1.000000, 1.000000),\n",
    "(0.498039, 1.000000, 0.000000),\n",
    "(0.000000, 0.803922, 0.000000),\n",
    "(0.000000, 0.545098, 0.000000),\n",
    "(0.062745, 0.305882, 0.545098),\n",
    "(0.117647, 0.564706, 1.000000),\n",
    "(0.000000, 0.698039, 0.933333),\n",
    "(0.000000, 0.933333, 0.933333),\n",
    "(0.537255, 0.407843, 0.803922),\n",
    "(0.568627, 0.172549, 0.933333),\n",
    "(0.545098, 0.000000, 0.545098),\n",
    "(0.545098, 0.000000, 0.000000),\n",
    "(0.803922, 0.000000, 0.000000),\n",
    "(0.933333, 0.250980, 0.000000),\n",
    "(1.000000, 0.498039, 0.000000),\n",
    "(0.803922, 0.521569, 0.000000),\n",
    "(1.000000, 0.843137, 0.000000)]\n",
    "cmap = mcolors.ListedColormap(cmap_data, 'precip_rss')\n",
    "\n",
    "#clevs = [0,0.01,0.1,0.25,0.5,0.75,1.00,1.5,2,2.5,3,3.5,4,5,6,8,10]  ### inches\n",
    "clevs = [0,0.25,2.5,5,10,20,25,37.5,50,62.5,75,87.5,100,125,150,200,250]  ## mm\n",
    "norm = mcolors.BoundaryNorm(clevs, cmap.N)\n",
    "\n",
    "\n",
    "def plot_background(ax,minlon,maxlon,minlat,maxlat):\n",
    "    ax.set_extent([minlon,maxlon,minlat,maxlat])\n",
    "    #ax.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=0.5)\n",
    "    ax.add_feature(cfeature.STATES.with_scale('10m'), linewidth=1)\n",
    "    ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=1)\n",
    "\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                      linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.left_labels = True\n",
    "    gl.bottom_labels = True\n",
    "    gl.right_labels = False\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.x_inline = False\n",
    "    gl.y_inline = False\n",
    "    gl.ylocator = LatitudeLocator()\n",
    "    gl.xformatter = LongitudeFormatter()\n",
    "    gl.yformatter = LatitudeFormatter()\n",
    "    gl.rotate_labels = False\n",
    "    gl.xlabel_style = {'size': 7}\n",
    "    gl.ylabel_style = {'size': 7}\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7342d-163d-45d3-bbdd-149515a3ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = ccrs.LambertConformal(central_longitude=-105., central_latitude=40.)\n",
    "lon2d,lat2d = np.meshgrid(data_sub.lon,data_sub.lat)\n",
    "\n",
    "datasets_to_plot = ['stage4','era5','gfs','hrrr','hrrr_smooth','hrrr_smooth']\n",
    "\n",
    "fig, ax_dict = plt.subplot_mosaic([datasets_to_plot[0:2],\n",
    "                                   datasets_to_plot[2:4],\n",
    "                                  datasets_to_plot[4:6]],\n",
    "                              layout='constrained',\n",
    "                               figsize=(8,10),\n",
    "                               subplot_kw={'projection': crs})\n",
    "\n",
    "axlist = []\n",
    "for k, ax in ax_dict.items():\n",
    "    axlist=axlist+[ax]\n",
    "    plot_background(ax,minlon,maxlon,minlat,maxlat)\n",
    "\n",
    "for ds in datasets_to_plot:\n",
    "    cf = ax_dict[ds].contourf(lon2d,lat2d,data_sub[ds],\n",
    "                         clevs, cmap=cmap, norm=norm, \n",
    "                              extend='max',\n",
    "                         transform_first=True,\n",
    "                         transform=ccrs.PlateCarree())\n",
    "\n",
    "plt.suptitle(\"precipitation analysis/forecast comparison for 24 h ending \"+str(vtime), \n",
    "            fontweight='semibold')\n",
    "\n",
    "cb = plt.colorbar(cf, ax=axlist, orientation='vertical', \n",
    "                  ticks=clevs, norm=norm, aspect=50, shrink=0.85, pad=0.01)\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "cb.set_label('precipitation (mm)', fontsize=10)\n",
    "\n",
    "### label panels, from here: \n",
    "### https://matplotlib.org/stable/gallery/text_labels_and_annotations/label_subplots.html#sphx-glr-gallery-text-labels-and-annotations-label-subplots-py\n",
    "for label, ax in ax_dict.items():\n",
    "    ax.annotate(\n",
    "        label,\n",
    "        xy=(0, 1), xycoords='axes fraction',\n",
    "        xytext=(+0.5, -0.5), textcoords='offset fontsize',\n",
    "        fontsize=12, fontweight='semibold', verticalalignment='top',\n",
    "        bbox=dict(facecolor='white', edgecolor='black', pad=3.0))\n",
    "\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf4ba5-2c3c-45ec-9fbb-e5941e5b7817",
   "metadata": {},
   "source": [
    "## OK, now let's actually calculate some verification stats! We will use the 'scores' package which makes this fairly straightforward for a wide variety of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74dca45-acde-4c47-83f6-6c1d295b4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import scores.categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14171c1f-b819-4092-ab58-5f97d5358084",
   "metadata": {},
   "source": [
    "### first we can use a single rainfall threshold, and inspect the contingency table for a forecast\n",
    "#### Building off of the example here: https://scores.readthedocs.io/en/stable/tutorials/Binary_Contingency_Scores.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9c432-168e-4a02-b619-b573888c9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.25  ### 0.25 mm = 0.01 inch which is generally used as 'measureable' rain\n",
    "\n",
    "event_operator = scores.categorical.ThresholdEventOperator(default_event_threshold=threshold, default_op_fn=operator.ge)\n",
    "\n",
    "### GFS forecast, compared to 'truth' of Stage IV\n",
    "c_man = event_operator.make_contingency_manager(data_sub['gfs'], data_sub['stage4'])\n",
    "\n",
    "c_man.get_table()  ### the 5 entries in the array are: true positive, true negative, false positive, false negative, and total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a719a0-5c84-4cbc-b07d-ba09384d36ac",
   "metadata": {},
   "source": [
    "#### now we can see some of the scores that can be computed from the contingency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44b561-bfa8-4cd5-af5a-d03fc349c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GFS statistics:\")\n",
    "print(\"POD/recall = \"+str(c_man.probability_of_detection().values))\n",
    "print(\"success ratio/precision = \"+str(c_man.success_ratio().values))\n",
    "print(\"critical success index = \"+str(c_man.critical_success_index().values))\n",
    "print(\"equitable threat score = \"+str(c_man.equitable_threat_score().values))\n",
    "print(\"F1 score = \"+str(c_man.f1_score().values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e67a35-4924-4f95-a3e8-e196e914f128",
   "metadata": {},
   "source": [
    "### let's now loop over multiple rainfall thresholds and calculate the scores for those. We'll compile everything into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ce14b-2eeb-4370-853e-87f83d967a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time = True  ### for first time through loop\n",
    "\n",
    "for threshold in [0.25,2.5,5,10,25,35,50]:\n",
    "    print(\"threshold: \"+str(threshold)+\" mm\")\n",
    "\n",
    "    event_operator = scores.categorical.ThresholdEventOperator(default_event_threshold=threshold, \n",
    "                                                               default_op_fn=operator.ge)\n",
    "\n",
    "    first_ds = True\n",
    "    for ds in datasets_to_plot[1:-1]:\n",
    "        c_man = event_operator.make_contingency_manager(data_sub[ds], data_sub['stage4'])\n",
    "\n",
    "        scores_df_this = pd.DataFrame([c_man.probability_of_detection().values,\n",
    "                          c_man.success_ratio().values,\n",
    "                          c_man.critical_success_index().values,\n",
    "                          c_man.equitable_threat_score().values,\n",
    "                          c_man.f1_score().values,\n",
    "                          c_man.heidke_skill_score().values], columns=[ds])\n",
    "\n",
    "        scores_df_this['score'] = [\"POD\",\"SR\",\"CSI\",\"ETS\",\"F1\",\"HSS\"] ### list of scores shown above\n",
    "        scores_df_this['threshold'] = threshold\n",
    "\n",
    "        if first_ds:\n",
    "            scores_df = scores_df_this\n",
    "            first_ds = False\n",
    "        else:\n",
    "            scores_df = pd.concat([scores_df, scores_df_this[ds]], axis=1)\n",
    "\n",
    "    if first_time:\n",
    "        scores_df_all = scores_df\n",
    "        first_time = False\n",
    "    else:\n",
    "        scores_df_all = pd.concat([scores_df_all, scores_df])\n",
    "\n",
    "scores_df_all.set_index(['score','threshold'], inplace=True)\n",
    "scores_df_all\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09b059-882f-4bbe-9e43-49b2689f0576",
   "metadata": {},
   "source": [
    "### and now we can make some plots of these scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507946a-cb2f-4738-bdeb-110448924198",
   "metadata": {},
   "source": [
    "#### ETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05872eb6-f3d6-4980-9314-559a20d96054",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_all.xs('ETS', level='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475c9d2-b5df-4e19-ba03-1e6d5cbb9987",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_all.xs('ETS', level='score').plot(marker='o')\n",
    "\n",
    "plt.title(\"Equitable threat score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a490b7c-7647-4f41-9bd2-c109382c5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(scores_df_all.xs('ETS', level='score'),\n",
    "       title='Equitable threat score', markers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80550688-663c-46fe-9cf8-eb8e3f43b496",
   "metadata": {},
   "source": [
    "#### F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c30fe6-d0e0-40ab-b409-a18157de7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_all.xs('F1', level='score').plot(marker='o')\n",
    "\n",
    "plt.title(\"F1 score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9410bc2f-543b-4c60-8eae-7c714c07640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(scores_df_all.xs('F1', level='score'),\n",
    "       title='F1 score', markers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f20a6e-954b-4278-ba89-e31c3e7d6d2d",
   "metadata": {},
   "source": [
    "#### Heidke skill score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf54b9-048a-4a4c-b221-486f00fd1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_all.xs('HSS', level='score').plot(marker='o')\n",
    "\n",
    "plt.title(\"Heidke skill score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442070b-74e0-47d2-82a9-7e1d79e74d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(scores_df_all.xs('HSS', level='score'),\n",
    "       title='Heidke threat score', markers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c809c9-3301-411c-9a10-e0c0b736156a",
   "metadata": {},
   "source": [
    "## Performance diagram (Roebber 2009)\n",
    "#### Code adapted from DJ Gagne: https://gist.github.com/djgagne/64516e3ea268ec31fb34\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb63707-8357-41a7-a57d-d644c4b5bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_params=dict(loc=4, fontsize=8, framealpha=1, frameon=True)\n",
    "markers=['*','o','s','v','8']\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "grid_ticks = np.arange(0, 1.01, 0.01)\n",
    "sr_g, pod_g = np.meshgrid(grid_ticks, grid_ticks)\n",
    "bias = pod_g / sr_g\n",
    "csi = 1.0 / (1.0 / sr_g + 1.0 / pod_g - 1.0)\n",
    "csi_contour = plt.contourf(sr_g, pod_g, csi, np.arange(0.1, 1.1, 0.1), extend=\"max\", cmap=\"Blues\")\n",
    "b_contour = plt.contour(sr_g, pod_g, bias, [0.5, 1, 1.5, 2, 4], colors=\"k\", linestyles=\"dashed\")\n",
    "plt.clabel(b_contour, fmt=\"%1.1f\", manual=[(0.2, 0.9), (0.4, 0.9), (0.6, 0.9), (0.7, 0.7)])\n",
    "\n",
    "#### plot our data here:\n",
    "d=0\n",
    "for ds in scores_df_all.columns:\n",
    "    c = 0\n",
    "    for thresh in scores_df_all.xs('POD', level='score').index:\n",
    "        plt.plot(scores_df_all.xs('SR', level='score')[ds][thresh],\n",
    "                 scores_df_all.xs('POD', level='score')[ds][thresh],\n",
    "                marker=markers[d], markersize=10, markerfacecolor='none',\n",
    "                 markeredgecolor=colors[c], color=colors[c], markeredgewidth=2,\n",
    "                 label=ds+\", \"+str(thresh))\n",
    "        c=c+1\n",
    "    d=d+1\n",
    "                 \n",
    "cbar = plt.colorbar(csi_contour, pad=0.02, shrink=0.95, aspect=50)\n",
    "cbar.set_label(\"Critical Success Index\", fontsize=12)\n",
    "plt.xlabel(\"Success Ratio (1-FAR)\", fontsize=12)\n",
    "plt.ylabel(\"Probability of Detection\", fontsize=12)\n",
    "ticks=np.arange(0, 1.1, 0.1)\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks)\n",
    "plt.title(\"Performance diagram\", fontsize=13, fontweight=\"bold\")\n",
    "#plt.text(0.48,0.6,\"Frequency Bias\",fontdict=dict(fontsize=14, rotation=45))\n",
    "plt.legend(**legend_params)\n",
    "\n",
    "#plt.savefig(filename, dpi=dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f2b50-b9db-4527-a7d4-3d040b686714",
   "metadata": {},
   "source": [
    "## Synthesis and possible next steps\n",
    "\n",
    "- What did you take away from this analysis?\n",
    "- What happened when we smoothed out the HRRR forecast?\n",
    "- How do the results change if you use ERA5 as the 'truth' instead of Stage-IV?\n",
    "- What's not being captured by these statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841320f-82b4-4a98-bd7a-8e001b8659f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
