{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldOn_BV2GwKP",
        "outputId": "d9797ba5-5d76-4aed-e85b-3d86edd7401b",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# if necessary, install NeuralGCM and dependencies\n",
        "! pip install -q -U neuralgcm dinosaur-dycore gcsfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_web7Ad1gunN"
      },
      "source": [
        "# Forecasting quick start\n",
        "\n",
        "This notebook uses ERA5 data and pretrained NeuralGCM model to make a weather forecast.\n",
        "\n",
        "The forecast is made in 3 steps:\n",
        "1. Slice of ERA5 data is regridded to model resolution\n",
        "2. NeuralGCM model state is initialized and rolled out\n",
        "3. Predictions and reference trajectory are combined for visualization\n",
        "\n",
        "By default the notebook uses intermediate deterministic NeuralGCM 1.4째 model. Other available checkpoints include deterministic 0.7째, 2.8째 and stochastic 1.4째 NeuralGCM variations.\n",
        "\n",
        "```{tip}\n",
        "You can run this notebook yourself in [Google Colab](https://colab.research.google.com/github/google-research/neuralgcm/blob/main/docs/inference_demo.ipynb). We recommend using a GPU or TPU runtime due to high memory and compute requirements.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wTapB9c0AWMJ"
      },
      "outputs": [],
      "source": [
        "import gcsfs\n",
        "import jax\n",
        "import numpy as np\n",
        "import pickle\n",
        "import xarray\n",
        "\n",
        "from dinosaur import horizontal_interpolation\n",
        "from dinosaur import spherical_harmonic\n",
        "from dinosaur import xarray_utils\n",
        "import neuralgcm\n",
        "\n",
        "gcs = gcsfs.GCSFileSystem(token=\"anon\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5uFP46Obo80"
      },
      "source": [
        "## Load a pre-trained NeuralGCM model\n",
        "\n",
        "```{caution}\n",
        "Trained model weights are licensed for non-commercial use, under the Creative Commons [Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/) license (CC BY-NC-SA 4.0).\n",
        "```\n",
        "\n",
        "Pre-trained model checkpoints from the NeuralGCM paper are [available for download](https://console.cloud.google.com/storage/browser/gresearch/neuralgcm/04_30_2024) on Google Cloud Storage:\n",
        "\n",
        "- Deterministic models:\n",
        "    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_deterministic_0_7_deg.pkl`\n",
        "    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_deterministic_1_4_deg.pkl`\n",
        "    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_deterministic_2_8_deg.pkl`\n",
        "- Stochastic models:\n",
        "    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_stochastic_1_4_deg.pkl`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uQnv1GWKD1iP"
      },
      "outputs": [],
      "source": [
        "model_name = \"neural_gcm_dynamic_forcing_deterministic_2_8_deg.pkl\"  # @param ['neural_gcm_dynamic_forcing_deterministic_0_7_deg.pkl', 'neural_gcm_dynamic_forcing_deterministic_1_4_deg.pkl', 'neural_gcm_dynamic_forcing_deterministic_2_8_deg.pkl', 'neural_gcm_dynamic_forcing_stochastic_1_4_deg.pkl'] {type: \"string\"}\n",
        "\n",
        "with gcs.open(f\"gs://gresearch/neuralgcm/04_30_2024/{model_name}\", \"rb\") as f:\n",
        "    ckpt = pickle.load(f)\n",
        "\n",
        "model = neuralgcm.PressureLevelModel.from_checkpoint(ckpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpEb_avqbo80"
      },
      "source": [
        "## Load ERA5 data from GCP/Zarr\n",
        "\n",
        "See {doc}`datasets` for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66ZyTazL6GF7"
      },
      "source": [
        "Select out a few days of data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9Dbth-nDjM5F"
      },
      "outputs": [],
      "source": [
        "era5_path = \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\"\n",
        "full_era5 = xarray.open_zarr(gcs.get_mapper(era5_path), chunks=None)\n",
        "\n",
        "# https://en.wikipedia.org/wiki/October_2020_Arctic_blast_in_the_United_States\n",
        "demo_start_time = \"2020-10-23\"\n",
        "demo_end_time = \"2020-10-28\"\n",
        "data_inner_steps = 24  # process every 24th hour\n",
        "\n",
        "sliced_era5 = (\n",
        "    full_era5[model.input_variables + model.forcing_variables]\n",
        "    .pipe(\n",
        "        xarray_utils.selective_temporal_shift,\n",
        "        variables=model.forcing_variables,\n",
        "        time_shift=\"24 hours\",\n",
        "    )\n",
        "    .sel(time=slice(demo_start_time, demo_end_time, data_inner_steps))\n",
        "    .compute()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivRFAQnt6KKF"
      },
      "source": [
        "Regrid to NeuralGCM's native resolution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "62wVlyCsJ-Jg"
      },
      "outputs": [],
      "source": [
        "era5_grid = spherical_harmonic.Grid(\n",
        "    latitude_nodes=full_era5.sizes[\"latitude\"],\n",
        "    longitude_nodes=full_era5.sizes[\"longitude\"],\n",
        "    latitude_spacing=xarray_utils.infer_latitude_spacing(full_era5.latitude),\n",
        "    longitude_offset=xarray_utils.infer_longitude_offset(full_era5.longitude),\n",
        ")\n",
        "regridder = horizontal_interpolation.ConservativeRegridder(\n",
        "    era5_grid, model.data_coords.horizontal, skipna=True\n",
        ")\n",
        "eval_era5 = xarray_utils.regrid(sliced_era5, regridder)\n",
        "eval_era5 = xarray_utils.fill_nan_with_nearest(eval_era5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrbru3K1bo81"
      },
      "source": [
        "## Make the forecast\n",
        "\n",
        "See {doc}`trained_models` for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kVCC2pO8eZE0"
      },
      "outputs": [],
      "source": [
        "inner_steps = 24  # save model outputs once every 24 hours\n",
        "outer_steps = 5 * 24 // inner_steps  # total of 4 days\n",
        "timedelta = np.timedelta64(1, \"h\") * inner_steps\n",
        "times = np.arange(outer_steps) * inner_steps  # time axis in hours\n",
        "\n",
        "# initialize model state\n",
        "inputs = model.inputs_from_xarray(eval_era5.isel(time=0))\n",
        "input_forcings = model.forcings_from_xarray(eval_era5.isel(time=0))\n",
        "rng_key = jax.random.key(42)  # optional for deterministic models\n",
        "initial_state = model.encode(inputs, input_forcings, rng_key)\n",
        "\n",
        "# use persistence for forcing variables (SST and sea ice cover)\n",
        "all_forcings = model.forcings_from_xarray(eval_era5.head(time=1))\n",
        "\n",
        "# make forecast\n",
        "final_state, predictions = model.unroll(\n",
        "    initial_state,\n",
        "    all_forcings,\n",
        "    steps=outer_steps,\n",
        "    timedelta=timedelta,\n",
        "    start_with_input=True,\n",
        ")\n",
        "predictions_ds = model.data_to_xarray(predictions, times=times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7lhecHtbo82"
      },
      "source": [
        "## Compare forecast to ERA5\n",
        "\n",
        "See [WeatherBench2](https://sites.research.google/weatherbench/) for more comprehensive evaluations and archived NeuralGCM forecasts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# error(\"Stop here.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-GG0YrV7cMG"
      },
      "outputs": [],
      "source": [
        "# Selecting ERA5 targets from exactly the same time slice\n",
        "target_trajectory = model.inputs_from_xarray(\n",
        "    eval_era5.thin(time=(inner_steps // data_inner_steps)).isel(time=slice(outer_steps))\n",
        ")\n",
        "target_data_ds = model.data_to_xarray(target_trajectory, times=times)\n",
        "\n",
        "combined_ds = xarray.concat([target_data_ds, predictions_ds], \"model\")\n",
        "combined_ds.coords[\"model\"] = [\"ERA5\", \"NeuralGCM\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "EUoubIO67uTW",
        "outputId": "603d28bf-8105-4e1e-b220-9c00de30c265"
      },
      "outputs": [],
      "source": [
        "# Visualize ERA5 vs NeuralGCM trajectories\n",
        "combined_ds.specific_humidity.sel(level=850).plot(\n",
        "    x=\"longitude\", y=\"latitude\", row=\"time\", col=\"model\", robust=True, aspect=2, size=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sensitivity to local perturbations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# options for variables to perturb\n",
        "print(eval_era5.data_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Performs perturbation analysis on a specified variable at a given atmospheric level.\n",
        "\n",
        "** Note that the model replaces the ocean surface temperature with the SST from ERA5. **\n",
        "\n",
        "Variables:\n",
        "-----------\n",
        "perturbation_list : tuple\n",
        "    A tuple containing the perturbation magnitudes to be applied.\n",
        "lev : int\n",
        "    The atmospheric level (in hPa) at which the perturbation is applied.\n",
        "delta_var : str\n",
        "    The variable to be perturbed (e.g., \"temperature\").\n",
        "modify_type : str\n",
        "    The type of modification to be applied (e.g., \"region\" or \"point\").\n",
        "lat_pt : float\n",
        "    The latitude point for the perturbation.\n",
        "lon_pt : float\n",
        "    The longitude point for the perturbation.\n",
        "region : ndarray\n",
        "    A boolean array defining the region of interest based on latitude and longitude conditions.\n",
        "\n",
        "Computed Indices:\n",
        "-----------------\n",
        "ilev : int\n",
        "    The index of the closest atmospheric level to `lev`.\n",
        "ilat : int\n",
        "    The index of the closest latitude to `lat_pt`.\n",
        "ilon : int\n",
        "    The index of the closest longitude to `lon_pt`.\n",
        "\"\"\"\n",
        "\n",
        "perturbation_list = (0, -.01)  # in units of the variable you are modifying\n",
        "lev = \"column\"  # pressure level in hPa or \"column\"\n",
        "modify_type = \"region\"\n",
        "delta_var = \"specific_humidity\"\n",
        "\n",
        "lat_pt, lon_pt = 46.8721, 360-113.9940\n",
        "region = (np.abs(eval_era5.latitude) < 90) & (eval_era5.longitude > 0)\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "if lev == \"column\":\n",
        "    ilev = np.arange(eval_era5[\"level\"].size)\n",
        "else:\n",
        "    ilev = np.argmin(np.abs(eval_era5[\"level\"].values - lev)).item()\n",
        "ilat = np.argmin(np.abs(eval_era5[\"latitude\"].values - lat_pt))\n",
        "ilon = np.argmin(np.abs(eval_era5[\"longitude\"].values - lon_pt))\n",
        "\n",
        "print(f\"Perturbation being added to {delta_var} at level {lev} hPa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tkGJv8VEgFa"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "predictions_dict = {}\n",
        "\n",
        "for perturbation in perturbation_list:\n",
        "    print(f\"Running perturbation delta_{perturbation}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # get inputs and add perturbation to field\n",
        "    inputs = model.inputs_from_xarray(eval_era5.isel(time=0))\n",
        "    if modify_type == \"region\":\n",
        "        mod_data = np.where(\n",
        "            ~region.T,\n",
        "            inputs[delta_var][ilev, ...],\n",
        "            inputs[delta_var][ilev, ...] + perturbation,\n",
        "        )\n",
        "        inputs[delta_var][ilev, ...] = np.clip(mod_data, a_min=0, a_max=None)\n",
        "    elif modify_type == \"point\":\n",
        "        inputs[delta_var][ilev, ilon, ilat] = np.clip(\n",
        "            inputs[delta_var][ilev, ilon, ilat] + perturbation, a_min=0, a_max=None\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"modify_type must be either 'region' or 'point'\")\n",
        "\n",
        "    # define the time steps and output frequency\n",
        "    inner_steps = 24  # save model outputs once every 24 hours\n",
        "    outer_steps = 5 * 24 // inner_steps  # number of days\n",
        "    timedelta = np.timedelta64(1, \"h\") * inner_steps\n",
        "    times = np.arange(outer_steps) * inner_steps  # time axis in hours\n",
        "\n",
        "    # initialize model state\n",
        "    input_forcings = model.forcings_from_xarray(eval_era5.isel(time=0))\n",
        "    rng_key = jax.random.key(42)  # optional for deterministic models\n",
        "    initial_state = model.encode(inputs, input_forcings, rng_key)\n",
        "\n",
        "    # use persistence for forcing variables (SST and sea ice cover)\n",
        "    all_forcings = model.forcings_from_xarray(eval_era5.head(time=1))\n",
        "\n",
        "    # make forecast\n",
        "    final_state, predictions = model.unroll(\n",
        "        initial_state,\n",
        "        all_forcings,\n",
        "        steps=outer_steps,\n",
        "        timedelta=timedelta,\n",
        "        start_with_input=True,\n",
        "    )\n",
        "\n",
        "    predictions_dict[f\"delta_{perturbation}\"] = (\n",
        "        model.data_to_xarray(predictions, times=times)\n",
        "        .sel(level=[1000, 850, 500])\n",
        "        .load()\n",
        "    )\n",
        "\n",
        "    print(f\"   elapsed time: {time.time() - start_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "var = \"specific_humidity\"\n",
        "level = 1000\n",
        "\n",
        "predictions_dict[\"delta_-0.01\"][var].sel(level=level).plot(x=\"longitude\", y=\"latitude\", col=\"time\", col_wrap=5, robust=True, cmap=\"Purples\", vmin=0)\n",
        "plt.show()\n",
        "\n",
        "diff_ds = predictions_dict[\"delta_-0.01\"][var].sel(level=level) - predictions_dict[\"delta_0\"][var].sel(level=level)\n",
        "diff_ds.plot(x=\"longitude\", y=\"latitude\", col=\"time\", col_wrap=5, robust=True, cmap=\"RdBu_r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "var = \"temperature\"\n",
        "level = 1000\n",
        "\n",
        "combined_ds.temperature.sel(model=\"ERA5\").sel(level=1000, latitude=46.8721, longitude=360-113.9940, method=\"nearest\").plot.line(x=\"time\", color=\"k\")\n",
        "predictions_dict[\"delta_0\"][var].sel(level=level, latitude=lat_pt, longitude=lon_pt, method=\"nearest\").plot.line(x=\"time\")\n",
        "predictions_dict[\"delta_-0.01\"][var].sel(level=level, latitude=lat_pt, longitude=lon_pt, method=\"nearest\").plot.line(x=\"time\")\n",
        "plt.legend([\"ERA5\", \"delta_0\", \"delta_-0.01\"])\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "neuralgcm-cpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
